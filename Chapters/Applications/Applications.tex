\chapter{Applications}
\label{ch:Applications}
\section{Introduction}
To measure the performance AUC values will be used. Using the AUC to measure the performance of SDMs has been criticized \parencite{lobo_auc:_2008, jimenez-valverde_insights_2012}. However, most of the issues that are usually raised are not of particular interest in our case. Furthermore, as far as we know there is no other popular and threshold independent performance measure. \\

The data-sets were split into a training and a test set. The training data consists of \nicefrac{3}{4}'th of the data while the test set contains the other \nicefrac{1}{4}'th.\\

\section{Implementations and tuning parameters of the methods}
For the majority of the methods described in Chapters \ref{ch:ReducingTheNumberOfExplanatoryVariables} and \ref{ch:ClassificationTechniques} some decisions regarding their model specification and tuning parameters have to be made.

In order to have a nice baseline method the logistic model was fit by using only linear terms. The logistic regression methods combined with the lasso or ridge were fit by using a cubic polynomial expansion of the predictors. To limit the amount of predictors and computational cost no interaction terms were considered. \\

It was decided to implement our own version of PCA logistic and KPCA logistic regression. This was mainly done to investigate the remarks made in Section \ref{sec:dimRedPrVSBG}. Both implementations allow us to specify on which indices the (K)PCA should be based on. Furthermore 5-fold-CV is used to select the an optimal number of principal components where always the components corresponding to the $x$ highest eigenvalues. To allow some non-linearity in the PCA logistic regressin implementation we also allow for polynomial expansions in the PCs of up to the third degree (ignoring interaction effects). CV is used to select the optimal polynomial expansion. This expanding of the PCs into a polynomial is not done when KPCA is used, the reason is that KPCA already implicitly expands the original data into a new non-linear expansion. To limit the computational costs it was decided to limit the number of components to at most $75$ in the KPCA implementation. Furthermore, when using KPCA together with logistic regression the KPCA will be performed on at most $500$ observations, if necessary these are randomly selected from the relevant observations. \\

In the MaxEnt implementation where CV was used to select the regularization parameters considered were $\chi \times \lambda_{def}$ with $\lambda_{def}$ the default MaxEnt parameter and $\chi \in \{0.1,0.5,1,2,10\}$. \\

The tuning variables and of the ANN method are the number of neurons and the in the hidden layer $\in \{ 5,10,20,40,60 \}$. Following the suggestions of \cite{venables_modern_2002} we optimize the weight decay parameter over $\{0.1,0.01,0.001,0.0001\}$. Furthermore instead of simply averaging neural networks it was decided to use bagging which has, next to the advantages mentioned in Section \ref{}, the advantage that it tends to prevent over-fitting. The only tuning parameter that is used in the vanilla ANN model is the number of neurons in the hidden layer. \\

The tuning parameters of our gradient boosted decision trees are the number of trees $\in \{ 100,500,1000,2000\}$, the interaction depth $\in \{ 1,3,5,7\}$, and the amount of shrinkage $\in  \{0.1,0.01,0.001,0.0001)\}$. The choice of these values was mainly inspired by \cite{elith_working_2008}. \\



\section{Results}
\subsection{Presence-only data}

\begin{table}[!htb]
\center
\begin{tabular}{lcccc}

 & \multicolumn{2}{c}{All variables} & \multicolumn{2}{c}{Bioclimatic variables}\\
\cline{2-3} \cline{4-5} \\
Method & Mean AUC & SE & Mean AUC & SE \\
\midrule
Logistic: vanilla               & 0.933 & 0.036 & 0.889& 0.080 \\
Logistic: backward              & 0.817 & 0.238 & 0.926& 0.031 \\
Logistic: forward               & 0.682 & 0.231 & 0.493& 0.211 \\
Logistic: PCA                   & 0.875 & 0.074 & 0.857& 0.094 \\
Logistic: presence PCA          & 0.779 & 0.205 & 0.855& 0.100 \\
Logistic: background PCA        & 0.877 & 0.077 & 0.872& 0.076 \\
Logistic: kernel PCA            & 0.937 & 0.030 & 0.916& 0.049 \\
Logistic: presence kernel PCA   & 0.946 & 0.031 & 0.924& 0.046 \\
Logistic: background kernel PCA & 0.941 & 0.027 & 0.929& 0.030 \\
Logistic: lasso                 & 0.939 & 0.031 & 0.924& 0.044 \\
Logistic: ridge                 & 0.934 & 0.033 & 0.905& 0.051 \\
Logistic: select07              & 0.931 & 0.039 & 0.900& 0.061 \\
GAM: auto selection             & 0.927 & 0.072 & 0.927& 0.027 \\
GAM: vanilla                    & 0.908 & 0.084 & 0.926& 0.037 \\
GAM: select07                   & 0.936 & 0.046 & 0.929& 0.032 \\
MaxEnt                          & 0.902 & 0.056 & 0.918& 0.038 \\
MaxEnt Vanilla                  & 0.867 & 0.117 & 0.910& 0.044 \\
ANN                             & 0.951 & 0.032 & 0.941& 0.033 \\
ANN: vanilla                    & 0.931 & 0.039 & 0.921& 0.039 \\
GBM                             & 0.958 & 0.030 & 0.941& 0.028 \\
\bottomrule
\end{tabular}
\end{table}


\begin{figure}[!htb]
\center
\makebox[\textwidth][c]{%
	\includegraphics[scale=0.70]{Plots/AUCPlot.png}
}
\end{figure}


\subsection{Presence-absence data}
\todo[inline]{speed-up computations => subset of absence points => only influences the intercept => same AUC etc.}

\begin{table}[!htb]
\center
\begin{tabular}{lcccc}
 & \multicolumn{2}{c}{All variables} & \multicolumn{2}{c}{Bioclimatic variables}\\
\cline{2-3} \cline{4-5} \\
Method & Mean AUC & SE & Mean AUC & SE \\
\midrule
Logistic: vanilla    & 0.961 & 0.027 & 0.961& 0.027 \\
Logistic: backward   & 0.682 & 0.301 & 0.682& 0.301 \\
Logistic: forward    & 0.774 & 0.284 & 0.774& 0.284 \\
Logistic: PCA        & 0.913 & 0.084 & 0.913& 0.084 \\
Logistic: kernel PCA & 0.950 & 0.052 & 0.950& 0.052 \\
Logistic: lasso      & 0.960 & 0.042 & 0.960& 0.042 \\
Logistic: ridge      & 0.957 & 0.044 & 0.957& 0.044 \\
Logistic: select07   & 0.756 & 0.239 & 0.756& 0.239 \\
GAM: auto selection  & 0.925 & 0.098 & 0.925& 0.098 \\
GAM: vanilla         & 0.877 & 0.117 & 0.877& 0.117 \\
GAM: select07        & 0.948 & 0.062 & 0.948& 0.062 \\
ANN                  & 0.973 & 0.020 & 0.973& 0.020 \\
ANN: vanilla         & 0.962 & 0.036 & 0.962& 0.036 \\
GBM                  & 0.977 & 0.014 & 0.977& 0.014 \\
\bottomrule

\end{tabular}
\end{table}




\begin{figure}[!htb]
\center
\makebox[\textwidth][c]{%
	\includegraphics[scale=0.70]{Plots/AUCPAPlot.png}
}
\end{figure}

\section{Discussion}